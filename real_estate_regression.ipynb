{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "real-estate-regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ItayShalit/Intro-to-Deep-Learning/blob/main/real_estate_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-15T10:33:06.722585Z",
          "iopub.execute_input": "2022-05-15T10:33:06.722861Z",
          "iopub.status.idle": "2022-05-15T10:33:06.727857Z",
          "shell.execute_reply.started": "2022-05-15T10:33:06.722826Z",
          "shell.execute_reply": "2022-05-15T10:33:06.726571Z"
        },
        "trusted": true,
        "id": "ihgptErGdOQi"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade git+https://github.com/noahgolmant/pytorch-hessian-eigenthings.git@master#egg=hessian-eigenthings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DF5_-bgUfTPs",
        "outputId": "acf07c6d-d416-4e2b-a192-9ca29fc2f42d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hessian-eigenthings\n",
            "  Cloning https://github.com/noahgolmant/pytorch-hessian-eigenthings.git (to revision master) to /tmp/pip-install-rany0q_h/hessian-eigenthings_3a8ed45907e8497e92333fb2eae70471\n",
            "  Running command git clone -q https://github.com/noahgolmant/pytorch-hessian-eigenthings.git /tmp/pip-install-rany0q_h/hessian-eigenthings_3a8ed45907e8497e92333fb2eae70471\n",
            "Requirement already satisfied: numpy>=0.14 in /usr/local/lib/python3.7/dist-packages (from hessian-eigenthings) (1.21.6)\n",
            "Requirement already satisfied: torch>=0.4 in /usr/local/lib/python3.7/dist-packages (from hessian-eigenthings) (1.11.0+cu113)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from hessian-eigenthings) (1.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4->hessian-eigenthings) (4.2.0)\n",
            "Building wheels for collected packages: hessian-eigenthings\n",
            "  Building wheel for hessian-eigenthings (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hessian-eigenthings: filename=hessian_eigenthings-0.0.2-py3-none-any.whl size=9671 sha256=7e73213bf98b1c277181c4983ff9740e4f7f62b98c2fdea274ac61180bc1e192\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-axh3e4rm/wheels/7d/a8/45/394ac423a7268a364a0a0453ca63748540b398a050e674af66\n",
            "Successfully built hessian-eigenthings\n",
            "Installing collected packages: hessian-eigenthings\n",
            "Successfully installed hessian-eigenthings-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from hessian_eigenthings import compute_hessian_eigenthings\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.utils.data as data_utils\n",
        "from matplotlib import pyplot as plt\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-15T11:17:06.687776Z",
          "iopub.execute_input": "2022-05-15T11:17:06.688155Z",
          "iopub.status.idle": "2022-05-15T11:17:06.709428Z",
          "shell.execute_reply.started": "2022-05-15T11:17:06.688121Z",
          "shell.execute_reply": "2022-05-15T11:17:06.708322Z"
        },
        "trusted": true,
        "id": "XVwi5tOpdOQk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_url = \"https://raw.githubusercontent.com/ItayShalit/Intro-to-Deep-Learning/main/real-estate-data.csv\"\n"
      ],
      "metadata": {
        "id": "0k7bbaawfCut"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = 'Y house price of unit area'\n",
        "df = pd.read_csv(data_url).drop('No', axis = 1)\n",
        "std_scaler = StandardScaler()\n",
        "df_scaled = std_scaler.fit_transform(df.drop(target, axis = 1).to_numpy())\n",
        "df_scaled = pd.DataFrame(df_scaled, columns=[col for col in df.columns if col != 'Y house price of unit area'])\n",
        "df = pd.concat([df_scaled, df], axis = 1)\n",
        "\n",
        "train, test = train_test_split(df, test_size = 0.25)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-15T10:41:34.364540Z",
          "iopub.execute_input": "2022-05-15T10:41:34.365123Z",
          "iopub.status.idle": "2022-05-15T10:41:34.380837Z",
          "shell.execute_reply.started": "2022-05-15T10:41:34.365087Z",
          "shell.execute_reply": "2022-05-15T10:41:34.379706Z"
        },
        "trusted": true,
        "id": "Zrp3VSw-dOQk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "batch_size = len(train) #Training full batch\n",
        "\n",
        "train_target = torch.tensor(train[target].values.astype(np.float32))\n",
        "train = torch.tensor(train.drop(target, axis = 1).values.astype(np.float32)) \n",
        "train_tensor = data_utils.TensorDataset(train, train_target) \n",
        "train_loader = data_utils.DataLoader(dataset = train_tensor, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "test_target = torch.tensor(test[target].values.astype(np.float32))\n",
        "test = torch.tensor(test.drop(target, axis = 1).values.astype(np.float32)) \n",
        "test_tensor = data_utils.TensorDataset(test, test_target) \n",
        "test_loader = data_utils.DataLoader(dataset = test_tensor, batch_size = batch_size, shuffle = True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-15T10:41:38.034505Z",
          "iopub.execute_input": "2022-05-15T10:41:38.034775Z",
          "iopub.status.idle": "2022-05-15T10:41:38.046984Z",
          "shell.execute_reply.started": "2022-05-15T10:41:38.034748Z",
          "shell.execute_reply": "2022-05-15T10:41:38.046286Z"
        },
        "trusted": true,
        "id": "-7s3dvhbdOQm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# labels = ['train_accuracy', 'test_accuracy', 'train_loss', 'test_loss']\n",
        "\n",
        "def calculate_gradient_l2_norm(model):\n",
        "    mean_l2_norm = 0\n",
        "    grad_num = 0\n",
        "    for p in list(filter(lambda p: p.grad is not None, model.parameters())):\n",
        "        grad_num += len(p)\n",
        "    for p in list(filter(lambda p: p.grad is not None, model.parameters())):\n",
        "        mean_l2_norm += (p.grad.data.norm(2).item())*(len(p)/grad_num)\n",
        "    return mean_l2_norm\n",
        "\n",
        "def train_loop(dataloader, model, loss_fn, optimizer, device, print_progress = False):\n",
        "    model.train()\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if print_progress&(batch % 100 == 0):\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn, device, return_results = False):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    \n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    if return_results:\n",
        "        return test_loss, correct\n",
        "\n",
        "def train_and_return_results(trainloader, testloader, model, loss_fn, optimizer, epochs, device):\n",
        "    loss_values, loss_grad_l2_norm, min_eigenvalues_of_hessian, max_eigenvalues_of_hessian  = [], [], [], []\n",
        "    for t in range(epochs):\n",
        "        train_loop(trainloader, model, loss_fn, optimizer, device)\n",
        "        test_loss, test_accuracy = test_loop(testloader, model, loss_fn, device, True)\n",
        "        loss_values.append(test_loss)\n",
        "        loss_grad_l2_norm.append(calculate_gradient_l2_norm(model))\n",
        "        eigenvals, eigenvecs = compute_hessian_eigenthings(model, trainloader,\n",
        "                                                   loss_fn, 12)\n",
        "        if t%5 == 0:\n",
        "          min_eigenvalues_of_hessian.append(min(eigenvals))\n",
        "          max_eigenvalues_of_hessian.append(max(eigenvals))\n",
        "    return loss_values, loss_grad_l2_norm, min_eigenvalues_of_hessian, max_eigenvalues_of_hessian\n",
        "  \n",
        "def plot_results(results):\n",
        "  figure = plt.figure(figsize=(18, 6))\n",
        "  ax1 = figure.add_subplot(1,2,1)\n",
        "  ax2 = figure.add_subplot(1,2,2)\n",
        "  ax1 = figure.get_axes()[0]\n",
        "  ax2 = figure.get_axes()[1]\n",
        "  full_x_axis = [i for i in range(epochs)]\n",
        "  five_interval_x_axis = [i for i in range(epochs) if i%5 == 0]\n",
        "  ax1.plot(full_x_axis, results[0], label='Objective Value')\n",
        "  ax1.plot(full_x_axis, results[1], label='L2 Norm of Loss Gradients')\n",
        "  ax2.plot(five_interval_x_axis, results[2], label='Min Eigenvalue of Hessian')\n",
        "  ax2.plot(five_interval_x_axis, results[3], label='Max Eigenvalue of Hessian')\n",
        "  ax1.legend()\n",
        "  ax2.legend()\n",
        "  figure.show()\n",
        "\n",
        "def train_and_plot_results(trainloader, testloader, model, loss_fn, optimizer, epochs, device):\n",
        "    results = train_and_return_results(trainloader, testloader, model, loss_fn, optimizer, epochs, device)\n",
        "    plot_results(results)"
      ],
      "metadata": {
        "id": "B3Rlq3OEdOQn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_stack = nn.Sequential(\n",
        "            nn.Linear(12, 512),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.Linear(512, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_stack(x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "def NNClassGeneratorByDepth(depth):\n",
        "  class FFNeuralNetwork(nn.Module):\n",
        "      def __init__(self):\n",
        "          super(FFNeuralNetwork, self).__init__()\n",
        "          self.flatten = nn.Flatten()\n",
        "          sequence = OrderedDict()\n",
        "          sequence['lin1'] = nn.Linear(12, 128)\n",
        "          for i in range(depth-1):\n",
        "            sequence[f'lin{i+2}'] = nn.Linear(128, 128)\n",
        "          sequence[f'lin{depth + 1}'] = nn.Linear(128, 1)\n",
        "          self.linear_relu_stack = nn.Sequential(sequence)\n",
        "\n",
        "      def forward(self, x):\n",
        "          x = self.flatten(x)\n",
        "          logits = self.linear_relu_stack(x)\n",
        "          return logits\n",
        "  return FFNeuralNetwork"
      ],
      "metadata": {
        "id": "x3NxpOQudORC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "learning_rate = 0.001\n",
        "momentum_param = 0.95\n",
        "epochs = 4\n",
        "\n",
        "# for depth in [2,3,4]:\n",
        "for depth in [2]:\n",
        "  NNClass = NNClassGeneratorByDepth(depth)\n",
        "  model = NNClass().to(device)\n",
        "  print(model)\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum_param)\n",
        "  train_and_plot_results(train_loader, test_loader, model, loss_fn, optimizer, epochs, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UEYkjt4dORD",
        "outputId": "27dd98ee-303b-4af0-e16a-460a8ae857cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "FFNeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (lin1): Linear(in_features=12, out_features=128, bias=True)\n",
            "    (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (lin3): Linear(in_features=128, out_features=1, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([310])) that is different to the input size (torch.Size([310, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([104])) that is different to the input size (torch.Size([104, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [=============================================================>...]  Step: 21ms | Tot: 430ms | power iter error: 0.0034\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/20 \n",
            " [=============================================================>...]  Step: 20ms | Tot: 481ms | power iter error: 0.0008\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/20 \n",
            " [=============================================================>...]  Step: 35ms | Tot: 444ms | power iter error: 0.0001\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/20 \n",
            " [=============================================================>...]  Step: 50ms | Tot: 915ms | power iter error: nan\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/20 \n",
            " [=============================================================>...]  Step: 39ms | Tot: 948ms | power iter error: nan\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/20 \n",
            " [=============================================================>...]  Step: 45ms | Tot: 806ms | power iter error: nan\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/20 \n",
            " [=============================================================>...]  Step: 40ms | Tot: 812ms | power iter error: nan\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/20 \n",
            " [=============================================================>...]  Step: 40ms | Tot: 824ms | power iter error: nan\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/20 \n",
            " [=============================================================>...]  Step: 40ms | Tot: 818ms | power iter error: nan\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/20 \n",
            " [=============================================================>...]  Step: 42ms | Tot: 834ms | power iter error: nan\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/20 \n",
            " [=============================================================>...]  Step: 42ms | Tot: 821ms | power iter error: nan\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/20 \n",
            " [=============================================================>...]  Step: 42ms | Tot: 843ms | power iter error: nan\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/20 \n",
            " [=============================================================>...]  Step: 42ms | Tot: 830ms | power iter error: nan\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/20 \n",
            " [=============================================================>...]  Step: 43ms | Tot: 814ms | power iter error: nan\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/20 \n",
            " [=============================================================>...]  Step: 46ms | Tot: 817ms | power iter error: nan\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/20 \n",
            " [=============================================================>...]  Step: 45ms | Tot: 817ms | power iter error: nan\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/20 \n",
            " [=============================================================>...]  Step: 56ms | Tot: 814ms | power iter error: nan\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/20 \n",
            " [=============================================================>...]  Step: 46ms | Tot: 821ms | power iter error: nan\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/20 \n",
            " [=============================================================>...]  Step: 45ms | Tot: 830ms | power iter error: nan\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/20 \n",
            " [=============================================================>...]  Step: 46ms | Tot: 824ms | power iter error: nan\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/20 \n",
            " [=============================================================>...]  Step: 39ms | Tot: 834ms | power iter error: nan\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/20 \n",
            " [=============================================================>...]  Step: 40ms | Tot: 809ms | power iter error: nan\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/20 \n",
            " [=============================================================>...]  Step: 44ms | Tot: 829ms | power iter error: nan\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/20 \n",
            " [=============================================================>...]  Step: 48ms | Tot: 823ms | power iter error: nan\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/20 \n",
            " [=============================================================>...]  Step: 46ms | Tot: 903ms | power iter error: nan\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/20 \n",
            " [=============================================================>...]  Step: 43ms | Tot: 825ms | power iter error: nan\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/20 \n",
            " [=============================================================>...]  Step: 46ms | Tot: 846ms | power iter error: nan\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/20 \n",
            " [=============================================================>...]  Step: 25ms | Tot: 779ms | power iter error: nan\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/20 \n",
            " [=============================================================>...]  Step: 38ms | Tot: 817ms | power iter error: nan\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/20 \n",
            " [=============================================================>...]  Step: 50ms | Tot: 813ms | power iter error: nan\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/20 \n",
            " [=============================================================>...]  Step: 42ms | Tot: 819ms | power iter error: nan\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/20 \n",
            " [=============================================================>...]  Step: 39ms | Tot: 821ms | power iter error: nan\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/20 \n",
            " [=============================================================>...]  Step: 42ms | Tot: 838ms | power iter error: nan\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20/20 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zVMm-58ydORE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}